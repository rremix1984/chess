# 🤖 动态Ollama模型获取功能说明

## 📋 功能概述

现在游戏启动时会自动检查本地可用的ollama大模型，并在AI选择下拉框中动态列出这些模型，无需手动修改代码。

## ✨ 主要特性

### 1. 自动模型检测
- **启动检测**: 游戏启动时自动执行 `ollama list` 命令
- **动态列表**: AI模型选择下拉框自动填充可用模型
- **智能降级**: 当ollama不可用时，自动使用默认模型列表

### 2. 支持的游戏界面
- ✅ **中国象棋** (`GameFrame.java`)
- ✅ **国际象棋** (`InternationalChessFrame.java`) 
- ✅ **五子棋** (`GomokuFrame.java`)

### 3. 错误处理机制
- **服务检测**: 自动检测ollama服务是否运行
- **异常处理**: 网络错误或命令失败时的优雅降级
- **用户提示**: 控制台显示详细的状态信息

## 🛠️ 技术实现

### 核心组件: `OllamaModelManager`

```java
public class OllamaModelManager {
    // 获取可用模型列表
    public static List<String> getAvailableModels()
    
    // 检查ollama服务状态
    public static boolean isOllamaAvailable()
    
    // 获取默认模型
    public static String getDefaultModel()
}
```

### 实现原理

1. **命令执行**: 使用 `ProcessBuilder` 执行 `ollama list`
2. **输出解析**: 解析命令输出，提取模型名称
3. **错误处理**: 捕获异常并提供默认模型列表
4. **界面更新**: 动态更新JComboBox内容

## 🚀 使用方法

### 步骤1: 确保ollama已安装
```bash
# 检查ollama安装状态
./check_ollama.sh
```

### 步骤2: 启动ollama服务
```bash
# 前台启动（推荐用于调试）
ollama serve

# 或后台启动
nohup ollama serve &
```

### 步骤3: 下载模型（可选）
```bash
# 下载推荐的象棋AI模型
ollama pull deepseek-r1:7b
ollama pull qwen2.5:7b
ollama pull hemanth/chessplayer:latest
```

### 步骤4: 启动游戏
```bash
# 编译并启动
mvn clean compile
java -cp "target/classes:target/dependency/*" com.example.App
```

## 📊 状态信息说明

### 成功状态
```
✅ 成功获取到 3 个ollama模型: [deepseek-r1:7b, qwen2.5:7b, hemanth/chessplayer:latest]
```

### 降级状态
```
⚠️ ollama命令执行失败，使用默认模型列表
使用默认模型列表: [deepseek-r1:7b, hemanth/chessplayer:latest, mxbai-embed-large:latest]
```

### 错误状态
```
⚠️ 获取ollama模型列表失败: java.io.IOException: Cannot run program "ollama"
```

## 🔧 故障排除

### 问题1: "ollama server not responding"
**解决方案:**
```bash
# 启动ollama服务
ollama serve
```

### 问题2: "could not find ollama app"
**解决方案:**
```bash
# 安装ollama
curl -fsSL https://ollama.ai/install.sh | sh
```

### 问题3: 权限错误
**解决方案:**
```bash
# 检查ollama安装路径
which ollama

# 确保有执行权限
chmod +x $(which ollama)
```

### 问题4: 模型列表为空
**解决方案:**
```bash
# 下载至少一个模型
ollama pull deepseek-r1:7b
```

## 🎯 最佳实践

### 1. 推荐模型配置
- **轻量级**: `qwen2.5:7b` (约4GB)
- **专业级**: `deepseek-r1:7b` (约4GB)
- **象棋专用**: `hemanth/chessplayer:latest` (约1GB)

### 2. 性能优化
- **预热模型**: 游戏启动前先运行一次模型
- **内存管理**: 根据系统内存选择合适大小的模型
- **并发控制**: 避免同时运行多个大模型

### 3. 开发建议
- **测试环境**: 使用较小的模型进行开发测试
- **生产环境**: 部署时确保ollama服务自动启动
- **监控日志**: 关注控制台输出的模型获取状态

## 📈 未来扩展

### 计划功能
- [ ] **模型信息显示**: 显示模型大小、下载状态等详细信息
- [ ] **自动下载**: 检测到缺失的推荐模型时提示下载
- [ ] **模型性能评估**: 根据硬件配置推荐最适合的模型
- [ ] **云端模型支持**: 支持远程ollama服务器

### 配置文件支持
```json
{
  "ollama": {
    "server_url": "http://localhost:11434",
    "preferred_models": ["deepseek-r1:7b", "qwen2.5:7b"],
    "fallback_models": ["deepseek-r1:7b"]
  }
}
```

## 🎉 总结

这个功能让象棋游戏更加智能和用户友好：

- ✅ **自动化**: 无需手动配置模型列表
- ✅ **灵活性**: 支持任意ollama模型
- ✅ **健壮性**: 优雅处理各种错误情况
- ✅ **易用性**: 一键启动，自动检测

现在你可以轻松地添加新模型，游戏会自动识别并在界面中显示！🚀